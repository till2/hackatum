[2024-11-19 14:09:44,013][train_rotation][INFO] - [Starting Epoch 0]
  0%|                                                                                                                                                                                                                                                             | 0/3 [00:00<?, ?it/s][2024-11-19 14:09:44,649] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing training_step
[2024-11-19 14:09:44,827] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper
[2024-11-19 14:09:47,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2024-11-19 14:09:48,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2024-11-19 14:09:48,581] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper
[2024-11-19 14:09:49,066] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in training_step>
[2024-11-19 14:09:49,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2024-11-19 14:09:50,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2024-11-19 14:09:50,520] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in training_step>
[2024-11-19 14:09:50,583] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _use_grad
[2024-11-19 14:09:50,587] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing step
[2024-11-19 14:09:50,590] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in step>
[2024-11-19 14:09:50,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing adamw
[2024-11-19 14:09:50,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in adamw>
 33%|█████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                   | 1/3 [00:06<00:13,  6.75s/it][2024-11-19 14:09:51,285] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing inference_step
[2024-11-19 14:09:51,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing inference_step (RETURN_VALUE)
[2024-11-19 14:09:51,456] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper
[2024-11-19 14:09:51,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2024-11-19 14:09:52,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2024-11-19 14:09:52,779] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper
[2024-11-19 14:09:52,844][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8474..1.1613001].
[2024-11-19 14:09:52,911][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.86338234..1.1609].
[2024-11-19 14:09:52,935][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8474..1.1613001].
[2024-11-19 14:09:52,960][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8577733..1.1613001].
[2024-11-19 14:09:52,984][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8498588..1.1436882].
[2024-11-19 14:09:53,008][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8474..1.1613001].
[2024-11-19 14:09:53,032][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8474..1.1613001].
[2024-11-19 14:09:53,056][matplotlib.image][WARNING] - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.8658412..1.1613001].
 33%|█████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                   | 1/3 [00:10<00:20, 10.01s/it]
Traceback (most recent call last):                                                                                                                                                                                                                                                      
  File "/home/agesp/hackatum/ml_stuff/train.py", line 332, in <module>
    train()
  File "/home/agesp/hackatum/ml_stuff/train.py", line 304, in train
    val_step(model, val_dl, loss_fn, global_step)
  File "/home/agesp/hackatum/ml_stuff/train.py", line 215, in val_step
    correct += (outputs == label).any(dim=1).sum().item()
RuntimeError: The size of tensor a (2) must match the size of tensor b (8) at non-singleton dimension 1
Traceback (most recent call last):
  File "/home/agesp/hackatum/ml_stuff/train.py", line 332, in <module>
    train()
  File "/home/agesp/hackatum/ml_stuff/train.py", line 304, in train
    val_step(model, val_dl, loss_fn, global_step)
  File "/home/agesp/hackatum/ml_stuff/train.py", line 215, in val_step
    correct += (outputs == label).any(dim=1).sum().item()
RuntimeError: The size of tensor a (2) must match the size of tensor b (8) at non-singleton dimension 1

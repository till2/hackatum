{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bb10a5-277f-4467-9fcb-bc9af3108fa3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c62fe-f6ab-4e14-8e3f-70da4e67b86a",
   "metadata": {},
   "source": [
    "In this notebook we introduce the methodology of using an open source language model (classifier) to classify strings into a set of arbitrary categories. \n",
    "\n",
    "The language model we will use is pretrained on a large dataset (just like the models underpinning OpenAI's recently famous ChatGPT interface). This model in particular has been trained and released by Facebook and has been optimized on the task of classification instead of text generation, but the underlying techniques are similar. It therefore is able to perform the tasks we want directly out-of-the-box without any further tweaking!\n",
    "\n",
    "Classification is the act of assigning a probability between one and zero to a (set of) labels given some string. The label with the highest probability wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c2278f-b205-4b52-bd40-d0f9cc78a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline helper from the transformers package, which we will use to load our model\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7554df-f0c3-498b-a9bc-871edac07d68",
   "metadata": {},
   "source": [
    "We will now instantiate the pretrained model and the `pipeline` object that we will be using to classify the strings. This is the `facebook/bart-large-mnli` model, which is trained on the Multi-Genre Natural Language Inference (MNLI) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68d2122-0c3a-4b65-89a5-9fa37a7e3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.18k/1.18k [00:00<00:00, 2.02MB/s]\n",
      "Downloading (…)/main/config.json: 100%|██████████| 3.26k/3.26k [00:00<00:00, 6.50MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.63G/1.63G [01:05<00:00, 24.7MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 190/190 [00:00<00:00, 372kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 3.61MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.45MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.26M/1.26M [00:00<00:00, 5.07MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and instantiate the facebook/bart-large-mnli model and pipeline. The first time this cell runs, it downloads a large file containing the model weights (1.5GB of parameters all in all!). \n",
    "# Let it finish and from then on it will be cached on disk.\n",
    "\n",
    "# Stay aware that this model instantiation uses a lot of memory/RAM, as it has to load the full 1.5GB of model parameters. If you load the model as below in several notebooks at the same time, you might overload your box. \n",
    "# To avoid this, when you're done with a notebook, close it's \"kernel\" on the left side of the Jupyterlabs interface (The second icon. circle with a square inside, selects the active kernels). This unloads the model from memory.\n",
    "\n",
    "c = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af6ed7-1077-45f6-b858-e7e20e293312",
   "metadata": {},
   "source": [
    "We will now test the model by giving it a string and asking it to classify the string into a set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063d10db-799f-4f8a-803e-e1bb12cf48a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'The sun is out today.', 'labels': ['Happy'], 'scores': [0.9892874369621277]}\n"
     ]
    }
   ],
   "source": [
    "c('The sun is out today.', ['Happy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
